{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee7f3f6fa5041fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.381324369Z",
     "start_time": "2024-01-31T21:32:00.239114527Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pathlib\n",
    "import mlflow\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa35ef398085195",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEBUG = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.386994222Z",
     "start_time": "2024-01-31T21:32:00.379528368Z"
    }
   },
   "id": "fc1af53ccd3bef24",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e864384eafcd657",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.421198581Z",
     "start_time": "2024-01-31T21:32:00.389353686Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pl.set_random_seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0015b125fead6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Constants definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325d69d614419b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "592739ccc636e342",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.422128807Z",
     "start_time": "2024-01-31T21:32:00.399895406Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DATA_PATH: pathlib.Path = pathlib.Path().absolute().parent.parent / 'data' / 'predict-energy-behavior-of-prosumers'\n",
    "\n",
    "CLIENTS_PATH: pathlib.Path = BASE_DATA_PATH / 'client.csv'\n",
    "ELECTRICITY_PATH: pathlib.Path = BASE_DATA_PATH / 'electricity_prices.csv'\n",
    "GAS_PATH: pathlib.Path = BASE_DATA_PATH / 'gas_prices.csv'\n",
    "HISTORICAL_WEATHER_PATH: pathlib.Path = BASE_DATA_PATH / 'historical_weather.csv'\n",
    "WEATHER_FORECAST_PATH: pathlib.Path = BASE_DATA_PATH / 'forecast_weather.csv'\n",
    "TRAIN_PATH: pathlib.Path = BASE_DATA_PATH / 'train.csv'\n",
    "WEATHER_STATION_COUNTY_PATH: pathlib.Path = BASE_DATA_PATH / 'weather_station_to_county_mapping.csv'\n",
    "COUNTY_MAP_PATH: pathlib.Path = BASE_DATA_PATH / \"county_id_to_name_map.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8d767f4c07bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "684f863546d6de36",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.435133345Z",
     "start_time": "2024-01-31T21:32:00.421451648Z"
    }
   },
   "outputs": [],
   "source": [
    "DATE_FORMAT: str = '%Y-%m-%d'\n",
    "DATETIME_FORMAT: str = '%Y-%m-%d %H:%M:%S'\n",
    "TIMEZONE: str = \"Europe/Tallinn\"\n",
    "ESTONIAN_HOLIDAYS = list(\n",
    "    holidays.country_holidays(\"EE\", years=range(2021, 2026)).keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9999667d83cf4492"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31da8cc56e8c4166",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.445122703Z",
     "start_time": "2024-01-31T21:32:00.434578337Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_clients(clients_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    \n",
    "    if not clients_df:\n",
    "        clients: pl.LazyFrame = pl.scan_csv(CLIENTS_PATH)\n",
    "    else:\n",
    "        clients = pl.from_pandas(clients_df).lazy()\n",
    "        \n",
    "    return clients.with_columns(\n",
    "        [\n",
    "            pl.col(\"product_type\").cast(pl.Int8),\n",
    "            pl.col(\"county\").cast(pl.Int8),\n",
    "            pl.col(\"eic_count\").cast(pl.Int16),\n",
    "            pl.col(\"installed_capacity\").cast(pl.Float32),\n",
    "            pl.col(\"is_business\").cast(pl.Int8),\n",
    "            pl.col(\"date\").str.to_date(DATE_FORMAT),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b23ab0d443cddfe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.480549529Z",
     "start_time": "2024-01-31T21:32:00.444573846Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_electricity(electricity_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    if not electricity_df:\n",
    "        electricity: pl.LazyFrame = pl.scan_csv(ELECTRICITY_PATH)\n",
    "    else:\n",
    "        electricity = pl.from_pandas(electricity_df).lazy()\n",
    "\n",
    "    electricity = electricity.drop([\"origin_date\"]).with_columns(\n",
    "        [\n",
    "            pl.col(\"forecast_date\").str.to_datetime(DATETIME_FORMAT) + pl.duration(days=1),\n",
    "            pl.col(\"euros_per_mwh\").cast(pl.Float32),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16)\n",
    "        ]\n",
    "    ).rename({\"forecast_date\": \"datetime\", \"euros_per_mwh\": \"electricity_euros_per_mwh\"})\n",
    "    return electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27a4b590ca70d365",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.492835541Z",
     "start_time": "2024-01-31T21:32:00.480040468Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_gas(gas_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    if not gas_df:\n",
    "        gas: pl.LazyFrame = pl.scan_csv(GAS_PATH)\n",
    "    else:\n",
    "        gas: pl.LazyFrame = pl.from_pandas(gas_df).lazy()\n",
    "\n",
    "    gas = gas.drop([\"origin_date\"]).with_columns(\n",
    "        [\n",
    "            pl.col(\"forecast_date\").str.to_date(DATE_FORMAT),\n",
    "            pl.col(\"lowest_price_per_mwh\").cast(pl.Float32),\n",
    "            pl.col(\"highest_price_per_mwh\").cast(pl.Float32),\n",
    "            ((pl.col(\"lowest_price_per_mwh\") + pl.col(\"highest_price_per_mwh\")) / 2).alias(\"gas_mean_price_per_mhw\"),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16)\n",
    "        ]\n",
    "    ).rename({\"forecast_date\": \"date\", \"lowest_price_per_mwh\": \"gas_lowest_price_per_mwh\", \"highest_price_per_mwh\": \"gas_highest_price_per_mwh\"})\n",
    "    return gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a9b3b2038318184",
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.502021091Z",
     "start_time": "2024-01-31T21:32:00.492508233Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_weather_county_map() -> pl.LazyFrame:\n",
    "    weather_station_county_mapping: pl.LazyFrame = pl.scan_csv(WEATHER_STATION_COUNTY_PATH)\n",
    "    weather_station_county_mapping = weather_station_county_mapping.with_columns([\n",
    "        pl.col(\"longitude\").cast(pl.Float32).round(decimals=2),\n",
    "        pl.col(\"latitude\").cast(pl.Float32).round(decimals=2),\n",
    "        pl.col(\"county\").cast(pl.Int8).fill_null(-1),\n",
    "        pl.col(\"county_name\").fill_null(\"Unknown\")\n",
    "    ])\n",
    "    \n",
    "    weather_station_county_mapping = weather_station_county_mapping.join(other=weather_station_county_mapping.group_by(\"county\").agg([\n",
    "        pl.col(\"longitude\").min().alias(\"longitude_min\"),\n",
    "        pl.col(\"longitude\").max().alias(\"longitude_max\"),\n",
    "        pl.col(\"latitude\").min().alias(\"latitude_min\"),\n",
    "        pl.col(\"latitude\").max().alias(\"latitude_max\"),\n",
    "    ]),\n",
    "        on=[\"county\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    return weather_station_county_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9925c7c2c7a5de0",
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.527178591Z",
     "start_time": "2024-01-31T21:32:00.501621166Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_weather_forecast(weather_station_county_mapping: pl.LazyFrame, weather_forecast_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    if not weather_forecast_df:\n",
    "        weather_forecast: pl.LazyFrame = pl.scan_csv(WEATHER_FORECAST_PATH)\n",
    "    else:\n",
    "        weather_forecast: pl.LazyFrame = pl.from_pandas(weather_forecast_df).lazy()\n",
    "    \n",
    "    weather_forecast: pl.LazyFrame = weather_forecast.drop([\"origin_datetime\"]).rename({\"forecast_datetime\": \"datetime\"})\n",
    "    # weather_forecast = weather_forecast.filter(pl.col(\"hours_ahead\") >= 24)  # we don't need to forecast for today\n",
    "    weather_forecast = weather_forecast.with_columns(\n",
    "        [\n",
    "            pl.col(\"datetime\").str.to_datetime(DATETIME_FORMAT),\n",
    "            pl.col(\"latitude\").cast(pl.Float32).round(decimals=2),\n",
    "            pl.col(\"longitude\").cast(pl.Float32).round(decimals=2),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    weather_forecast = weather_forecast.join(\n",
    "        other=weather_station_county_mapping,\n",
    "        how=\"left\",\n",
    "        on=[\"latitude\", \"longitude\"]\n",
    "    ).drop([\"latitude\", \"longitude\"])\n",
    "    \n",
    "    weather_forecast_mean = weather_forecast.group_by(\"county\", \"datetime\", \"data_block_id\").agg(\n",
    "            pl.col(\"hours_ahead\").mean(),\n",
    "            pl.col(\"temperature\").mean(),\n",
    "            pl.col(\"dewpoint\").mean(),\n",
    "            pl.col(\"cloudcover_high\").mean(),\n",
    "            pl.col(\"cloudcover_low\").mean(),\n",
    "            pl.col(\"cloudcover_mid\").mean(),\n",
    "            pl.col(\"cloudcover_total\").mean(),\n",
    "            pl.col(\"10_metre_u_wind_component\").mean(),\n",
    "            pl.col(\"10_metre_v_wind_component\").mean(),\n",
    "            pl.col(\"direct_solar_radiation\").mean(),\n",
    "            pl.col(\"surface_solar_radiation_downwards\").mean(),\n",
    "            pl.col(\"snowfall\").mean(),\n",
    "            pl.col(\"total_precipitation\").mean(),\n",
    "            pl.col(\"latitude_min\").first(),\n",
    "            pl.col(\"latitude_max\").first(),\n",
    "            pl.col(\"longitude_min\").first(),\n",
    "            pl.col(\"longitude_max\").first(),\n",
    "            pl.col(\"county_name\").first(),\n",
    "    )\n",
    "    \n",
    "    return weather_forecast_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10fc1bd7878d8537",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.537509252Z",
     "start_time": "2024-01-31T21:32:00.521163116Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_historical_weather(weather_station_county_mapping: pl.LazyFrame, historical_weather_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    if not historical_weather_df:\n",
    "        historical_weather: pl.LazyFrame = pl.scan_csv(HISTORICAL_WEATHER_PATH)\n",
    "    else:\n",
    "        historical_weather: pl.LazyFrame = pl.from_pandas(historical_weather_df).lazy()\n",
    "    \n",
    "    historical_weather = historical_weather.with_columns(\n",
    "        [\n",
    "            pl.col(\"datetime\").str.to_datetime(DATETIME_FORMAT),\n",
    "            pl.col(\"latitude\").cast(pl.Float32).round(decimals=2),\n",
    "            pl.col(\"longitude\").cast(pl.Float32).round(decimals=2),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    historical_weather = historical_weather.join(\n",
    "        other=weather_station_county_mapping,\n",
    "        how=\"left\",\n",
    "        on=[\"latitude\", \"longitude\"]\n",
    "    ).drop([\"latitude\", \"longitude\"])\n",
    "    \n",
    "    historical_weather_mean = historical_weather.group_by(\"county\", \"datetime\", \"data_block_id\").agg(\n",
    "        pl.col(\"temperature\").mean(),\n",
    "        pl.col(\"dewpoint\").mean(),\n",
    "        pl.col(\"rain\").mean(),\n",
    "        pl.col(\"snowfall\").mean(),\n",
    "        pl.col(\"surface_pressure\").mean(),\n",
    "        pl.col(\"cloudcover_total\").mean(),\n",
    "        pl.col(\"cloudcover_low\").mean(),\n",
    "        pl.col(\"cloudcover_mid\").mean(),\n",
    "        pl.col(\"cloudcover_high\").mean(),\n",
    "        pl.col(\"windspeed_10m\").mean(),\n",
    "        pl.col(\"winddirection_10m\").mean(),\n",
    "        pl.col(\"shortwave_radiation\").mean(),\n",
    "        pl.col(\"direct_solar_radiation\").mean(),\n",
    "        pl.col(\"diffuse_radiation\").mean(),\n",
    "        pl.col(\"latitude_min\").first(),\n",
    "        pl.col(\"latitude_max\").first(),\n",
    "        pl.col(\"longitude_min\").first(),\n",
    "        pl.col(\"longitude_max\").first(),\n",
    "        pl.col(\"county_name\").first(),\n",
    "        )\n",
    "    \n",
    "    # Test set has 1 day offset for hour<11 and 2 day offset for hour>11\n",
    "    historical_weather_mean = historical_weather_mean.with_columns(\n",
    "        pl.when(pl.col(\"datetime\").dt.hour() < 11).then(pl.col(\"datetime\") + pl.duration(days=1)).otherwise(pl.col(\"datetime\") + pl.duration(days=2))\n",
    "    )\n",
    "    \n",
    "    return historical_weather_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8222293b58141fbb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.550557374Z",
     "start_time": "2024-01-31T21:32:00.533894820Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_data(train_df: pd.DataFrame = None) -> pl.LazyFrame:\n",
    "    if not train_df:\n",
    "        train: pl.LazyFrame = pl.scan_csv(TRAIN_PATH)   \n",
    "    else:\n",
    "        train: pl.LazyFrame = pl.from_pandas(train_df).lazy()\n",
    "    \n",
    "    train = train.drop([\"prediction_unit_id\", \"row_id\"]).with_columns(\n",
    "            pl.col(\"datetime\").str.to_datetime(DATETIME_FORMAT),\n",
    "            pl.col(\"is_business\").cast(pl.Int8),\n",
    "            pl.col(\"product_type\").cast(pl.Int8),\n",
    "            pl.col(\"target\").cast(pl.Float32),\n",
    "            pl.col(\"is_consumption\").cast(pl.Int8),\n",
    "            pl.col(\"county\").cast(pl.Int8),\n",
    "            pl.col(\"data_block_id\").cast(pl.Int16),\n",
    "    )\n",
    "    return train.with_columns(\n",
    "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "            pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "            pl.col(\"datetime\").dt.ordinal_day().alias(\"day_of_year\"),\n",
    "            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_lagged_weather_forecast_features(weather_forecast: pl.LazyFrame):\n",
    "    lagged_weather_forecast = weather_forecast.sort(\"county\", \"datetime\", \"data_block_id\").rolling(index_column=\"datetime\", period=f\"1d\", by=[\"county\", \"data_block_id\"]).agg(\n",
    "        [\n",
    "            pl.col(\"temperature\").mean().alias(\"temperature_forecast_last_day\"),\n",
    "            pl.col(\"dewpoint\").mean().alias(\"dewpoint_forecast_last_day\"),\n",
    "            pl.col(\"snowfall\").mean().alias(\"snowfall_forecast_last_day\"),\n",
    "            pl.col(\"cloudcover_total\").mean().alias(\"cloudcover_total_forecast_last_day\"),\n",
    "            pl.col(\"cloudcover_low\").mean().alias(\"cloudcover_low_forecast_last_day\"),\n",
    "            pl.col(\"cloudcover_mid\").mean().alias(\"cloudcover_mid_forecast_last_day\"),\n",
    "            pl.col(\"cloudcover_high\").mean().alias(\"cloudcover_high_forecast_last_day\"),\n",
    "            pl.col(\"10_metre_u_wind_component\").mean().alias(\"10_metre_u_wind_component_forecast_last_day\"),\n",
    "            pl.col(\"10_metre_v_wind_component\").mean().alias(\"10_metre_v_wind_component_forecast_last_day\"),\n",
    "            pl.col(\"surface_solar_radiation_downwards\").mean().alias(\"surface_solar_radiation_downwards_forecast_last_day\"),\n",
    "            pl.col(\"direct_solar_radiation\").mean().alias(\"direct_solar_radiation_forecast_last_day\"),\n",
    "            pl.col(\"total_precipitation\").mean().alias(\"total_precipitation_forecast_last_day\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return lagged_weather_forecast\n",
    "\n",
    "def create_lagged_historical_weather_week_features(historical_weather: pl.LazyFrame):\n",
    "    lagged_historical_weather_week = historical_weather.sort(\"county\", \"datetime\", \"data_block_id\").rolling(index_column=\"datetime\", period=f\"1w\", by=[\"county\"]).agg(\n",
    "        [\n",
    "            pl.col(\"temperature\").mean().alias(\"temperature_last_7_days\"),\n",
    "            pl.col(\"dewpoint\").mean().alias(\"dewpoint_last_7_days\"),\n",
    "            pl.col(\"rain\").mean().alias(\"rain_last_7_days\"),\n",
    "            pl.col(\"snowfall\").mean().alias(\"snowfall_last_7_days\"),\n",
    "            pl.col(\"cloudcover_total\").mean().alias(\"cloudcover_total_last_7_days\"),\n",
    "            pl.col(\"cloudcover_low\").mean().alias(\"cloudcover_low_last_7_days\"),\n",
    "            pl.col(\"cloudcover_mid\").mean().alias(\"cloudcover_mid_last_7_days\"),\n",
    "            pl.col(\"cloudcover_high\").mean().alias(\"cloudcover_high_last_7_days\"),\n",
    "            pl.col(\"windspeed_10m\").mean().alias(\"windspeed_10m_last_7_days\"),\n",
    "            pl.col(\"winddirection_10m\").mean().alias(\"winddirection_10m_last_7_days\"),\n",
    "            pl.col(\"shortwave_radiation\").mean().alias(\"shortwave_radiation_last_7_days\"),\n",
    "            pl.col(\"direct_solar_radiation\").mean().alias(\"direct_solar_radiation_last_7_days\"),\n",
    "            pl.col(\"diffuse_radiation\").mean().alias(\"diffuse_radiation_last_7_days\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return lagged_historical_weather_week\n",
    "\n",
    "\n",
    "def create_lagged_historical_weather_day_features(historical_weather: pl.LazyFrame):\n",
    "    lagged_historical_weather_day = historical_weather.with_columns(pl.col(\"datetime\").dt.hour().alias(\"hour\")).sort(\"county\", \"datetime\").rolling(index_column=\"datetime\", period=f\"1d\", by=[\"county\"]).agg(\n",
    "        [\n",
    "            pl.col(\"temperature\").mean().alias(\"temperature_last_24_hours\"),\n",
    "            pl.col(\"dewpoint\").mean().alias(\"dewpoint_last_24_hours\"),\n",
    "            pl.col(\"rain\").mean().alias(\"rain_last_24_hours\"),\n",
    "            pl.col(\"snowfall\").mean().alias(\"snowfall_last_24_hours\"),\n",
    "            pl.col(\"cloudcover_total\").mean().alias(\"cloudcover_total_last_24_hours\"),\n",
    "            pl.col(\"cloudcover_low\").mean().alias(\"cloudcover_low_last_24_hours\"),\n",
    "            pl.col(\"cloudcover_mid\").mean().alias(\"cloudcover_mid_last_24_hours\"),\n",
    "            pl.col(\"cloudcover_high\").mean().alias(\"cloudcover_high_last_24_hours\"),\n",
    "            pl.col(\"windspeed_10m\").mean().alias(\"windspeed_10m_last_24_hours\"),\n",
    "            pl.col(\"winddirection_10m\").mean().alias(\"winddirection_10m_last_24_hours\"),\n",
    "            pl.col(\"shortwave_radiation\").mean().alias(\"shortwave_radiation_last_24_hours\"),\n",
    "            pl.col(\"direct_solar_radiation\").mean().alias(\"direct_solar_radiation_last_24_hours\"),\n",
    "            pl.col(\"diffuse_radiation\").mean().alias(\"diffuse_radiation_last_24_hours\"),\n",
    "        ]\n",
    "    )\n",
    "    return lagged_historical_weather_day"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.564863410Z",
     "start_time": "2024-01-31T21:32:00.544148115Z"
    }
   },
   "id": "6b635ca26087e0e7",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d41ef2ee0ac1933",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T21:32:00.577770454Z",
     "start_time": "2024-01-31T21:32:00.564504873Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_training_data(\n",
    "        train_df: pd.DataFrame = None,\n",
    "        clients_df: pd.DataFrame = None,\n",
    "        gas_df: pd.DataFrame = None,\n",
    "        electricity_df: pd.DataFrame = None,\n",
    "        historical_weather_df: pd.DataFrame = None,\n",
    "        weather_forecast_df: pd.DataFrame = None,\n",
    ") -> pl.LazyFrame:\n",
    "    client_ids_columns = [\"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "    data: pl.LazyFrame = (load_train_data(train_df)\n",
    "                          .join(other=load_clients(clients_df), how=\"left\", on=[\"county\", \"is_business\", \"product_type\", \"data_block_id\"], suffix=\"_client\")\n",
    "                          .join(other=load_gas(gas_df), on=\"data_block_id\", how=\"left\", suffix=\"_gas\")\n",
    "                          .join(other=load_electricity(electricity_df), on=[\"datetime\", \"data_block_id\"], how=\"left\", suffix=\"_electricity\")\n",
    "                        )\n",
    "\n",
    "    data = data.group_by(client_ids_columns).len().drop(\"len\").sort(client_ids_columns).with_row_index(name=\"client_id\").join(\n",
    "        other=data,\n",
    "        how=\"inner\",\n",
    "        on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "    )\n",
    "\n",
    "    weather_station_county_map = load_weather_county_map()\n",
    "    historical_weather = load_historical_weather(weather_station_county_map, historical_weather_df)\n",
    "    weather_forecast = load_weather_forecast(weather_station_county_map, weather_forecast_df)\n",
    "    \n",
    "    data = (data\n",
    "              .join(other=historical_weather, how=\"left\", on=[\"county\", \"datetime\", \"data_block_id\"], suffix=\"_measured\")\n",
    "              .join(other=weather_forecast, how=\"left\", on=[\"county\", \"datetime\", \"data_block_id\"], suffix=\"_forecast\")\n",
    "              )\n",
    "    \n",
    "    data = (data\n",
    "            .join(other=create_lagged_weather_forecast_features(weather_forecast), on=[\"county\", \"datetime\", \"data_block_id\"], how=\"left\")\n",
    "            .join(other=create_lagged_historical_weather_week_features(historical_weather), on=[\"county\", \"datetime\"], how=\"left\")\n",
    "            .join(other=create_lagged_historical_weather_day_features(historical_weather), on=[\"county\", \"datetime\"], how=\"left\")\n",
    "            )\n",
    "\n",
    "    n_day_lags = 7\n",
    "    # Create revealed targets for all day lags\n",
    "    revealed_targets = data.select(\"datetime\", \"client_id\", \"target\")\n",
    "    for day_lag in range(2, n_day_lags+1):\n",
    "        data = data.join(revealed_targets.with_columns(pl.col(\"datetime\") + pl.duration(days=day_lag)),\n",
    "                          how=\"left\",\n",
    "                          on=[\"datetime\", \"client_id\"],\n",
    "                          suffix=f'_{day_lag}_days_ago'\n",
    "                          )\n",
    "\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"product_type\").replace({0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}, default=\"Unknown\"),\n",
    "        pl.col(\"date\").dt.strftime(\"%Y-%m-%d\").is_in([x.strftime(\"%Y-%m-%d\") for x  in ESTONIAN_HOLIDAYS]).alias(\"is_holiday\")\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(pl.Int64).cast(pl.Int32),\n",
    "        pl.col(pl.Float64).cast(pl.Float32),\n",
    "    )\n",
    "\n",
    "    return data.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame()\n",
    "isinstance(a, pd.DataFrame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T22:10:03.092295025Z",
     "start_time": "2024-01-31T22:10:03.084776438Z"
    }
   },
   "id": "dea9765a61f79a4a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698f50c79db2774",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X: pd.DataFrame = create_training_data().collect().to_pandas()\n",
    "X[\"noise\"] = np.random.normal(0, 1, len(X)).astype(np.float32)\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = X[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5141c-434b-44b1-aa03-709115e81cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in sorted(X.columns):\n",
    "    print(col, X[col].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d626e773dc4be54",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652821edf3e8b931",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_selection( data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return data.drop(columns=[\n",
    "        \"client_id\",\n",
    "        \"data_block_id\",\n",
    "        \"date\",\n",
    "        \"date_client\",\n",
    "        \"date_gas\",\n",
    "        \"datetime\",\n",
    "        \"county\",\n",
    "        \"county_name_forecast\",\n",
    "        \"latitude_min_forecast\",\n",
    "        \"latitude_max_forecast\",\n",
    "        \"longitude_min_forecast\",\n",
    "        \"longitude_max_forecast\",\n",
    "        \"hour\",\n",
    "        \"quarter\",\n",
    "        \"year\"\n",
    "    ]).copy(deep=True)\n",
    "\n",
    "def train_model(dataframe: pd.DataFrame, train_indexes: list[int], test_indexes: list[int]) -> tuple:\n",
    "    dataframe = feature_selection(dataframe)\n",
    "    \n",
    "    x_train, x_test = dataframe.loc[train_indexes], dataframe.loc[test_indexes]\n",
    "    y_train, y_test = x_train.pop(\"target\"), x_test.pop(\"target\")\n",
    "\n",
    "    eval_results = {}    \n",
    "    model = lgb.LGBMRegressor(\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1_000,\n",
    "        subsample_for_bin=200_000,\n",
    "        objective=\"huber\",\n",
    "        class_weight=None,\n",
    "        min_split_gain=0.0,\n",
    "        min_child_weight=0.001,\n",
    "        min_child_samples=20,\n",
    "        subsample=1.0,\n",
    "        subsample_freq=0,\n",
    "        colsample_bytree=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        importance_type='split',\n",
    "        linear_tree=True,\n",
    "        verbosity=0,\n",
    "        device=\"gpu\",\n",
    "        bagging_seed=SEED\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=x_train, \n",
    "        y=y_train,\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[lgb.log_evaluation(), lgb.record_evaluation(eval_results), lgb.early_stopping(stopping_rounds=100)]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254925dd10e59e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc972823131604",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "def train_test_split(dataframe: pd.DataFrame, datetime_col: str = \"datetime\", train_months: int = 3, test_months: int = 1) -> Generator:\n",
    "    data_ = dataframe.copy(deep=True)\n",
    "    data_[\"month_year\"] = data_[datetime_col].dt.strftime('%Y-%m')\n",
    "    unique_months = data_[\"month_year\"].unique()\n",
    "    unique_months.sort()\n",
    "    for i, month_year in enumerate(unique_months[:-test_months], start=0):\n",
    "        year, month = month_year.split(\"-\")\n",
    "        year, month = int(year), int(month)\n",
    "        \n",
    "        if i < train_months:\n",
    "            train_month_start, train_month_end = unique_months[0], unique_months[i]\n",
    "        else:\n",
    "            train_month_start, train_month_end = unique_months[i-train_months+1], unique_months[i]\n",
    "        test_month_start, test_month_end = unique_months[i + 1], unique_months[i + test_months]\n",
    "\n",
    "        train = data_[(data_[\"month_year\"] >= train_month_start) & (data_[\"month_year\"] <= train_month_end)]\n",
    "        train_index = pd.concat([train, data_.query(\"month == @month & year < @year\")]).index\n",
    "        \n",
    "        test_index = data_[(data_[\"month_year\"] >= test_month_start) & (data_[\"month_year\"] <= test_month_end)].index\n",
    "        \n",
    "        yield train_index, test_index\n",
    "        \n",
    "        \n",
    "def get_train_split_from_test(data, test_data, train_months: int = 3, test_months: int = 1):\n",
    "    test_data_ = test_data.copy(deep=True)\n",
    "    data_ = data.copy(deep=True)\n",
    "\n",
    "    unique_month_year_test = test_data_[[\"year\", \"month\"]].unique().sort_values(by=[\"year\", \"month\"])\n",
    "    \n",
    "    for _, row in unique_month_year_test.iterrows():\n",
    "        train = data_[(data_[\"year\"] == row[\"year\"]) & (data_[\"month\"] >= row[\"month\"] - train_months) & (data_[\"month\"] < row[\"month\"])]\n",
    "        train_index = pd.concat([train, data_.query(\"month == @row.month & year < @row.year\")]).index\n",
    "\n",
    "        test_index = data_[(data_[\"year\"] == row[\"year\"]) & (data_[\"month\"] == row[\"month\"])]\n",
    "\n",
    "        yield train_index, test_index\n",
    "\n",
    "\n",
    "def training_loop(dataframe: pd.DataFrame):    \n",
    "    models = {\n",
    "        \"consumer\": [],\n",
    "        \"producer\": []\n",
    "    }\n",
    "    for is_consumer in [0, 1]:\n",
    "        client_type = \"consumer\" if is_consumer else \"producer\"\n",
    "        print(f\"Training for {client_type}\")\n",
    "\n",
    "        data = dataframe[dataframe.is_consumption == is_consumer].reset_index(drop=True).drop(columns=[\"is_consumption\"]).copy(deep=True)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(train_test_split(data, datetime_col=\"datetime\", train_months=15, test_months=6)):\n",
    "            models[client_type].append(train_model(data, train_index, test_index))\n",
    "    return models\n",
    "\n",
    "models = training_loop(dataframe=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "289478f5539d8b50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00271f-6ceb-4505-81e7-866523e1ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enefit\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reload enefit environment (only in debug mode, otherwise the submission will fail)\n",
    "if DEBUG:\n",
    "    enefit.make_env.__called__ = False\n",
    "    type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "    iter_test = env.iter_test()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a33999c2a577ba98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# List of target_revealed dataframes\n",
    "previous_revealed_targets = []\n",
    "\n",
    "for (test,\n",
    "     revealed_targets,\n",
    "     client_test,\n",
    "     historical_weather_test,\n",
    "     forecast_weather_test,\n",
    "     electricity_test,\n",
    "     gas_test,\n",
    "     sample_prediction) in iter_test:\n",
    "\n",
    "    # Rename test set to make consistent with train\n",
    "    test = test.rename(columns = {'prediction_datetime': 'datetime'})\n",
    "\n",
    "    # Initiate column data_block_id with default value to join on\n",
    "    id_column = 'data_block_id'\n",
    "\n",
    "    test[id_column] = 0\n",
    "    gas_test[id_column] = 0\n",
    "    electricity_test[id_column] = 0\n",
    "    historical_weather_test[id_column] = 0\n",
    "    forecast_weather_test[id_column] = 0\n",
    "    client_test[id_column] = 0\n",
    "    revealed_targets[id_column] = 0\n",
    "\n",
    "    data_test = FeatureProcessor(\n",
    "        data = test,\n",
    "        client = client_test,\n",
    "        historical_weather = historical_weather_test,\n",
    "        forecast_weather = forecast_weather_test,\n",
    "        electricity = electricity_test,\n",
    "        gas = gas_test\n",
    "    )\n",
    "\n",
    "    # Store revealed_targets\n",
    "    previous_revealed_targets.insert(0, revealed_targets)\n",
    "\n",
    "    if len(previous_revealed_targets) == N_day_lags:\n",
    "        previous_revealed_targets.pop()\n",
    "\n",
    "    # Add previous revealed targets\n",
    "    df_test = create_revealed_targets_test(data = data_test.copy(),\n",
    "                                           previous_revealed_targets = previous_revealed_targets.copy(),\n",
    "                                           N_day_lags = N_day_lags\n",
    "                                           )\n",
    "\n",
    "    # Make prediction\n",
    "    X_test = df_test[features]\n",
    "    sample_prediction['target'] = clf.predict(X_test)\n",
    "    env.predict(sample_prediction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bf4e1031a98dfe2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
